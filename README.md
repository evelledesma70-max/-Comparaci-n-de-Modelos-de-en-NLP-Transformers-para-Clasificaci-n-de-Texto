# -Comparaci-n-de-Modelos-de-en-NLP-Transformers-para-Clasificaci-n-de-Texto
Proyecto acad茅mico que compara distintos **modelos Transformer** aplicados a **clasificaci贸n de sentimientos** con el dataset **IMDB**, evaluando precisi贸n y rendimiento computacional.  ---

# Comparaci贸n de Modelos Transformer para Clasificaci贸n de Sentimientos

Este proyecto presenta una **evaluaci贸n comparativa de modelos de lenguaje basados en Transformers**
aplicados a la **clasificaci贸n de sentimientos** utilizando el **dataset IMDB**.

El estudio analiza tanto el rendimiento predictivo como la eficiencia computacional de diferentes
arquitecturas modernas de NLP.

---

##  Objetivo del Proyecto

Comparar modelos Transformer en tareas de clasificaci贸n de texto, evaluando su **precisi贸n** y su
**comportamiento computacional**, con el fin de identificar el mejor equilibrio entre desempe帽o y costo.

---

##  Modelos Evaluados

- ALBERT-base  
- ALBERT-large  
- ModernBERT-base  
- ModernBERT-large  

---

##  Dataset Utilizado

**IMDB Movie Reviews Dataset**
- Rese帽as de pel铆culas
- Clasificaci贸n binaria:
  - `positive`
  - `negative`

---

##  M茅tricas de Evaluaci贸n

- Accuracy
- Tiempo de inferencia
- Tiempo de carga del modelo
- Tama帽o del modelo
- Velocidad de procesamiento (samples/segundo)

---

## 锔 Metodolog铆a

1. Carga y preparaci贸n del dataset
2. Inferencia mediante `pipeline` de Hugging Face
3. Normalizaci贸n de etiquetas
4. Evaluaci贸n de m茅tricas de clasificaci贸n
5. Benchmark computacional
6. Visualizaci贸n comparativa de resultados

---

## 讹 Ejecuci贸n del Proyecto

```bash
pip install -r requirements.txt
python src/main.py

